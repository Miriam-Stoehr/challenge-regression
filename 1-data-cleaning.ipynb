{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImmoEliza Project - Part 3: Regression \n",
    "\n",
    "# Step 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataCleaner class with various methods for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataCleaner:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initializes the DataCleaner class with a DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): The input dataframe to be cleaned.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def handle_missing_values(self, column: str, strategy: str = 'fill', fill_value: str = 'Unknown') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Handles missing values for a specific column. By default, it fills missing values with a placeholder.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column name to handle missing values.\n",
    "            strategy (str): The strategy to handle missing values ('fill' or 'drop').\n",
    "            fill_value (str): The value to use for filling missing values if strategy is 'fill'.\n",
    "        \"\"\"\n",
    "        if strategy == 'fill':\n",
    "            self.df.loc[:, column] = self.df[column].fillna(fill_value)\n",
    "        elif strategy == 'drop':\n",
    "            self.df.dropna(subset=[column], inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Strategy must be 'fill' or 'drop'.\")\n",
    "        return self.df\n",
    "\n",
    "    def fill_missing_with_mode(self, column: str, strategy: str = 'fill') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Handles missing values for a specific column. By filling them with the mode.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column name to handle missing values.\n",
    "            strategy (str): The strategy to handle missing values ('fill' or 'drop').\n",
    "        \"\"\"\n",
    "        if strategy == 'fill':\n",
    "            mode_value = self.df[column].mode()[0]\n",
    "            self.df.loc[:, column] = self.df[column].fillna(mode_value)\n",
    "        elif strategy == 'drop':\n",
    "            self.df.dropna(subset=[column], inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Strategy must be 'fill' or 'drop'.\")\n",
    "        return self.df\n",
    "\n",
    "    def fill_missing_by_group(self, column: str, group_column: str, agg_func: str = 'median') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fills missing values in a column based on a group-specific statistic (e.g., median, mean).\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column with missing values to be filled.\n",
    "            group_column (str): The column to group by (e.g., 'subtype_of_property').\n",
    "            agg_func (str): The aggregation function to use ('median', 'mean', etc.).\n",
    "        \"\"\"\n",
    "        if agg_func == 'median':\n",
    "            fill_values = self.df.groupby(group_column)[column].median()\n",
    "        elif agg_func == 'mean':\n",
    "            fill_values = self.df.groupby(group_column)[column].mean()\n",
    "        else:\n",
    "            raise ValueError(\"Aggregation function must be 'median' or 'mean'.\")\n",
    "        \n",
    "        # Fill missing values with the group-specific statistic\n",
    "        self.df.loc[:, column] = self.df.apply(\n",
    "            lambda row: fill_values[row[group_column]] if pd.isnull(row[column]) else row[column],\n",
    "            axis=1\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    def drop_outliers(self, column: str, lower_bound: float = None, upper_bound: float = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drops rows where the values of a specified column are outside of the given bounds.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to filter outliers from.\n",
    "            lower_bound (float): The lower bound for valid values.\n",
    "            upper_bound (float): The upper bound for valid values.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the column is of type float64 and convert to int\n",
    "        if self.df[column].dtype == 'float64':\n",
    "            self.df.loc[:, column] = self.df[column].astype('int')\n",
    "\n",
    "        if lower_bound is not None:\n",
    "            self.df = self.df[self.df[column] >= lower_bound]\n",
    "        if upper_bound is not None:\n",
    "            self.df = self.df[self.df[column] <= upper_bound]\n",
    "        return self.df\n",
    "\n",
    "    def remove_substring(self, column:str, substring: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Removes a specified substring from all values in a given column.\n",
    "\n",
    "        Args:\n",
    "            column (str): The column from which to remove the substring.\n",
    "            substring (str): Substring to be removed.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The dataframe with the substring removed from the column.\n",
    "        \"\"\"\n",
    "        # Replace occurrences of the substring with an empty string\n",
    "        self.df.loc[:, column] = self.df[column].str.replace(substring, \"\", regex=False)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def binarize_column(self, column: str, threshold: float = 0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a specified column to binary values based on a threshold.\n",
    "        Values greater than the threshold are set to 1, otherwise 0.\n",
    "        \n",
    "        Args:\n",
    "            column: The column to binarize.\n",
    "            threshold: The threshold to determine binary classification.\n",
    "        \"\"\"\n",
    "        self.df.loc[:, column] = (self.df[column] > threshold).astype(int)\n",
    "        return self.df\n",
    "\n",
    "    def get_cleaned_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns the cleaned dataframe.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The cleaned dataframe.\n",
    "        \"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused part of DataCleaner\n",
    "def replace_smaller_value(self, column: str, condition_column: str):\n",
    "    \"\"\"\n",
    "    Replaces values in the 'column' with values from the 'condition_column' when a condition is met.\n",
    "    E.g., if the value in 'condition_column' is greater than the value in 'column', replace the value in 'column' with the value from 'condition_column'.\n",
    "    \n",
    "    Args:\n",
    "        column: The column to modify.\n",
    "        condition_column: The column whose value will be used for replacement.\n",
    "    \"\"\"\n",
    "    self.df.loc[:, column] = self.df.apply(\n",
    "        lambda row: row[condition_column] if row[condition_column] > row[column] else row[column], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataEncoder class with various methods for data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "class DataEncoder:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initializes the DataEncoder class with a DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): The input dataframe to be encoded.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def standardize_categories(self, column: str, mapping: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Standardizes categorical values based on a given mapping.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to standardize.\n",
    "            mapping (dict): A dictionary that maps old values to new values.\n",
    "        \"\"\"\n",
    "        self.df.loc[:, column] = self.df.loc[:, column].map(mapping)\n",
    "        return self.df\n",
    "    \n",
    "    def manual_mapping(self, column: str, mapping: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Applies manual mapping to a specified column using the provided dictionary.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to map.\n",
    "            mapping (dict): A dictionary defining the mapping of the column's values.\n",
    "        \"\"\"\n",
    "        # Ensure the column exists\n",
    "        if column not in self.df.columns:\n",
    "            raise KeyError(f\"Column '{column}' not found in DataFrame.\")\n",
    "        # Apply the mapping\n",
    "        self.df.loc[:, column] = self.df.loc[:, column].map(mapping)\n",
    "        return self.df\n",
    "\n",
    "    def encode_label(self, column: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encodes a categorical column using label encoding.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to encode.\n",
    "        \"\"\"\n",
    "        label_encoder = LabelEncoder()\n",
    "        self.df.loc[:, column] = label_encoder.fit_transform(self.df[column])\n",
    "        return self.df\n",
    "\n",
    "    def encode_onehot(self, column: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encodes a categorical column using one-hot encoding.\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to encode.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The original dataframe with new one-hot encoded columns.\n",
    "        \"\"\"\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        encoded_data = onehot_encoder.fit_transform(self.df[[column]])\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns=onehot_encoder.categories_[0])\n",
    "        self.df = pd.concat([self.df, encoded_df], axis=1)\n",
    "        self.df.drop(columns=[column], inplace=True)  # Drop original column after encoding\n",
    "        return self.df\n",
    "\n",
    "    def encode_ordinal(self, column: str, order: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Encodes a categorical column using ordinal encoding (custom order).\n",
    "        \n",
    "        Args:\n",
    "            column (str): The column to encode.\n",
    "            order (list): A list specifying the order of categories (ascending).\n",
    "        \"\"\"\n",
    "        ordinal_map = {category: index for index, category in enumerate(order)}\n",
    "        self.df.loc[:, column] = self.df[column].map(ordinal_map)\n",
    "        return self.df\n",
    "\n",
    "    def get_encoded_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns the dataframe with encoded categorical variables.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The dataframe with encoded columns.\n",
    "        \"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"./data/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26147, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataCleaner instance\n",
    "cleaner = DataCleaner(df)\n",
    "\n",
    "# Drop missing values in 'price' column\n",
    "df_cleaned = cleaner.handle_missing_values('price', strategy='drop')\n",
    "\n",
    "# Fill missing 'facade_number' based on median per 'subtype_of_property'\n",
    "df_cleaned = cleaner.fill_missing_by_group('facade_number', group_column='subtype_of_property', agg_func='median')\n",
    "\n",
    "# Drop outliers in 'living_area' (<12), 'facade_number' (>6), bedroom_nr (>24) -> since compared to other values of these data points, these entries don't seem realistic\n",
    "df_cleaned = cleaner.drop_outliers('living_area', lower_bound=12)\n",
    "df_cleaned = cleaner.drop_outliers('facade_number', upper_bound=6.0)\n",
    "df_cleaned = cleaner.drop_outliers('bedroom_nr', upper_bound=24)\n",
    "\n",
    "# Remove substring 'unit' from \"subtype_of_property\"\n",
    "df_cleaned = cleaner.remove_substring(\"subtype_of_property\", \" unit\")\n",
    "\n",
    "# Fill missing 'building_condition' with mode\n",
    "df_cleaned = cleaner.fill_missing_with_mode('building_condition', strategy='fill')\n",
    "\n",
    "# Change 'terrace' to binary (if value: 1, if not, 0)\n",
    "df_cleaned = cleaner.binarize_column('terrace', threshold=0)\n",
    "\n",
    "# Get cleaned dataframe\n",
    "df_cleaned = cleaner.get_cleaned_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apartment', 'penthouse', 'flat studio', 'ground floor', 'duplex',\n",
       "       'loft', 'service flat', 'kot', 'triplex', 'house', 'villa',\n",
       "       'apartment block', 'mansion', 'exceptional property',\n",
       "       'mixed use building', 'country cottage', 'town house', 'castle',\n",
       "       'bungalow', 'manor house', 'farmhouse', 'chalet', 'other property'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtypes = df_cleaned[\"subtype_of_property\"].unique()\n",
    "subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code               0\n",
       "commune                0\n",
       "province               0\n",
       "type_of_property       0\n",
       "subtype_of_property    0\n",
       "price                  0\n",
       "building_condition     0\n",
       "facade_number          0\n",
       "living_area            0\n",
       "equipped_kitchen       0\n",
       "bedroom_nr             0\n",
       "swimming_pool          0\n",
       "furnished              0\n",
       "open_fire              0\n",
       "terrace                0\n",
       "garden                 0\n",
       "plot_surface           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26102, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26102 entries, 0 to 26146\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   zip_code             26102 non-null  int64  \n",
      " 1   commune              26102 non-null  object \n",
      " 2   province             26102 non-null  object \n",
      " 3   type_of_property     26102 non-null  int64  \n",
      " 4   subtype_of_property  26102 non-null  object \n",
      " 5   price                26102 non-null  float64\n",
      " 6   building_condition   26102 non-null  object \n",
      " 7   facade_number        26102 non-null  float64\n",
      " 8   living_area          26102 non-null  int64  \n",
      " 9   equipped_kitchen     26102 non-null  object \n",
      " 10  bedroom_nr           26102 non-null  int64  \n",
      " 11  swimming_pool        26102 non-null  int64  \n",
      " 12  furnished            26102 non-null  int64  \n",
      " 13  open_fire            26102 non-null  int64  \n",
      " 14  terrace              26102 non-null  int64  \n",
      " 15  garden               26102 non-null  int64  \n",
      " 16  plot_surface         26102 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(5)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['installed', '0', 'hyper equipped', 'semi equipped',\n",
       "       'not installed', 'usa semi equipped', 'usa hyper equipped',\n",
       "       'usa installed', 'usa uninstalled'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_kitchens = df_cleaned[\"equipped_kitchen\"].unique()\n",
    "unique_kitchens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataEncoder instance\n",
    "encoder = DataEncoder(df_cleaned)\n",
    "\n",
    "# Data Encoding: Standardize 'equipped_kitchen' categories\n",
    "df_encoded = encoder.standardize_categories('equipped_kitchen', {\n",
    "    'installed': 'installed',\n",
    "    'semi equipped': 'semi equipped',\n",
    "    'hyper equipped': 'hyper equipped',\n",
    "    'not installed': 'not installed',\n",
    "    'usa installed': 'installed',\n",
    "    'usa hyper equipped': 'hyper equipped',\n",
    "    'usa semi equipped': 'semi equipped',\n",
    "    'usa uninstalled': 'not installed',\n",
    "    '0': 'not installed'\n",
    "})\n",
    "\n",
    "# Apply manual mapping to \"equipped_kitchen\" column\n",
    "kitchen_mapping = {\n",
    "    'not installed': 0,\n",
    "    'semi equipped': 1,\n",
    "    'installed': 2,\n",
    "    'hyper equipped': 3\n",
    "}\n",
    "\n",
    "df_encoded = encoder.manual_mapping('equipped_kitchen', kitchen_mapping)\n",
    "\n",
    "# Apply manual mapping to \"building_condition\" column -> start at 1, since 0 reserved for 'not present'\n",
    "condition_mapping = {\n",
    "    'as new': 6,\n",
    "    'just renovated': 5,\n",
    "    'good': 4,\n",
    "    'to be done up': 3,\n",
    "    'to renovate': 2,\n",
    "    'to restore': 1\n",
    "}\n",
    "\n",
    "df_encoded = encoder.manual_mapping('building_condition', condition_mapping)\n",
    "\n",
    "# Apply manual mapping to \"subtype_of_property\" column to reduce categories\n",
    "\n",
    "subtype_categories = {\n",
    "    'kot': 'apartment',\n",
    "    'chalet': 'house',\n",
    "    'flat studio': 'apartment',\n",
    "    'service flat': 'apartment',\n",
    "    'bungalow': 'house',\n",
    "    'town house': 'house',\n",
    "    'ground floor': 'apartment',\n",
    "    'apartment': 'apartment',\n",
    "    'house': 'house',\n",
    "    'mixed use building': 'mixed use building',\n",
    "    'triplex': 'house',\n",
    "    'farmhouse': 'mixed use building',\n",
    "    'loft': 'apartment',\n",
    "    'duplex': 'house',\n",
    "    'apartment block': 'mixed use building',\n",
    "    'country cottage': 'house',\n",
    "    'penthouse': 'luxury',\n",
    "    'mansion': 'luxury',\n",
    "    'other property': 'other',\n",
    "    'villa': 'luxury',\n",
    "    'exceptional property': 'luxury',\n",
    "    'manor house': 'luxury',\n",
    "    'castle': 'luxury'\n",
    "}\n",
    "\n",
    "df_encoded = encoder.manual_mapping('subtype_of_property', subtype_categories)\n",
    "\n",
    "# Apply manual mapping to reduced categories in \"subtypes of property\"\n",
    "\n",
    "subtype_mapping = {\n",
    "    'apartment':1,\n",
    "    'house': 2,\n",
    "    'mixed use building': 3,\n",
    "    'other': 4,\n",
    "    'luxury': 5\n",
    "}\n",
    "\n",
    "df_encoded = encoder.manual_mapping('subtype_of_property', subtype_mapping)\n",
    "\n",
    "# Get final encoded dataframe\n",
    "df_encoded = encoder.get_encoded_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 1], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_kitchens = df_encoded[\"equipped_kitchen\"].unique()\n",
    "unique_kitchens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 5, 3, 2, 1], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_conditions = df_encoded[\"building_condition\"].unique()\n",
    "unique_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 2, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtypes = df_encoded[\"subtype_of_property\"].unique()\n",
    "subtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
